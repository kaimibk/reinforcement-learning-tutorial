import random

import gymnasium as gym
from gymnasium import spaces
import numpy as np
from rich import print

class ServerRoomEnv(gym.Env):
    """
    Custom Environment that follows gym interface.
    The agent must keep the server room temperature near 20Â°C 
    by predicting heat generated by random CPU jobs.
    """
    def __init__(self, verbose=False):
        super(ServerRoomEnv, self).__init__()
        self.verbose = verbose
        
        # Target temperature
        self.target_temp = 20.0
        
        # Actions: 0 = Cool, 1 = Do Nothing, 2 = Heat
        self.action_space = spaces.Discrete(3)
        
        # Observation: Dictionary of Temp (Box) and Active CPUs (Discrete)
        # Temp ranges from 0-100 (float), CPUs range from 0-100 (int)
        self.observation_space = spaces.Dict(
            {
                "temperature": spaces.Box(
                    low=0.0, 
                    high=100.0, 
                    shape=(1,), 
                    dtype=np.float32
                ),
                "cpus": spaces.Discrete(101) # Allows integer values from 0 to 100
            }
        )
        
        # State variables
        self.current_temp = 20.0
        self.active_cpus = 0
        self.job_timer = 0  # Tracks how long the current job lasts
        
        self.episode_length = 60 # 60 steps per episode
        self.current_step = 0

    def _get_obs(self):
        """Helper method to format the observation dictionary."""
        return {
            "temperature": np.array([self.current_temp], dtype=np.float32),
            "cpus": int(self.active_cpus)
        }

    def reset(self, seed=None, options=None):
        """Restarts the environment for a new episode."""
        super().reset(seed=seed)
        
        # Start at a random temperature near the target
        self.current_temp = random.uniform(18.0, 22.0)
        self.active_cpus = 0
        self.job_timer = 0
        self.current_step = 0
        
        return self._get_obs(), {}

    def step(self, action):
        """Applies the action, processes jobs, and calculates the reward."""
        self.current_step += 1
        
        # 1. Apply Agent's Action Effects
        if action == 0:   # Cool
            self.current_temp -= 3.0
        elif action == 1: # Do Nothing
            pass
        elif action == 2: # Heat
            self.current_temp += 3.0
            
        # 2. Process Job Lifecycle
        if self.job_timer > 0:
            # Job is currently running
            self.job_timer -= 1
            if self.job_timer == 0:
                self.active_cpus = 0 # Job finished
        else:
            # No active job. 30% chance a new job arrives this step.
            if random.random() < 0.30:
                self.active_cpus = random.randint(10, 80) # Requires 10-80 CPUs
                self.job_timer = random.randint(3, 8)     # Lasts 3-8 timesteps
                
        # 3. Apply Environmental Heat (Calculated from active CPUs + slight noise)
        # Each active CPU adds 0.05 degrees, plus some minor fluctuation
        cpu_heat = (self.active_cpus * 0.05) 
        ambient_noise = random.uniform(-0.5, 0.5)
        self.current_temp += (cpu_heat + ambient_noise)
        
        # Clip temperature to stay within our defined bounds
        self.current_temp = np.clip(self.current_temp, 0.0, 100.0)
        
        # 4. Calculate Reward (Negative distance from target)
        reward = -abs(self.current_temp - self.target_temp)
        
        # 5. Check for Termination / Truncation
        terminated = False
        
        # Terminate if the servers melt or freeze (Failure condition)
        if self.current_temp >= 90.0:
            if self.verbose:
                print(f"\nðŸ”¥ [bold red]BOOM! Servers melted at {self.current_temp:.1f}Â°C! You exploded![/bold red] ðŸ”¥")
            terminated = True
        elif self.current_temp <= 5.0:
            if self.verbose:
                print(f"\nâ„ï¸ [bold blue]ICE AGE! Servers froze solid at {self.current_temp:.1f}Â°C! Welcome to Hoth![/bold blue] â„ï¸")
            terminated = True
        
        # Truncate if we hit the maximum time limit (Success condition)
        truncated = bool(self.current_step >= self.episode_length)
        if truncated and not terminated:
            if self.verbose:
                print("\nâœ… [bold green]SHIFT OVER! You survived the day without destroying the server room.[/bold green] âœ…")
            reward += 100.0 # Bonus for surviving the whole episode
        
        # 6. Format the return values
        info = {}
        return self._get_obs(), reward, terminated, truncated, info

    def render(self):
        """Simple text printout of the environment state."""
        print(f"Step: {self.current_step:02d} | Temp: {self.current_temp:.2f}Â°C | Active CPUs: {self.active_cpus}")

if __name__ == "__main__":
    # Instantiate our new environment
    env = ServerRoomEnv(verbose=True) # Set verbose to True to see detailed output

    # Reset the environment to start
    obs, info = env.reset()
    print(f"Starting Temperature: {obs['temperature'][0]:.2f}Â°C | Starting CPUs: {obs['cpus']}")

    episodes = 1
    for ep in range(episodes):
        obs, info = env.reset()
        done = False
        score = 0
        
        while not done:
            # Sample a random action from the action space (0, 1, or 2)
            action = env.action_space.sample()

            # Replace with your policy function later
            # action = my_cool_policy(obs)

            # Force the same action
            # action = 1 # Do Nothing (for testing)
            
            # Add keyboard input for manual control (optional)
            # action = int(input("Enter action (0=Cool, 1=Do Nothing, 2=Heat): "))

            # Step the environment forward
            obs, reward, terminated, truncated, info = env.step(action)
            score += reward
            
            env.render()
            
            # Episode ends if terminated (bounds exceeded) or truncated (time up)
            done = terminated or truncated

        print(f"Episode {ep + 1} finished with Total Reward: {score:.2f}")

    # Always close the environment when done
    env.close()
